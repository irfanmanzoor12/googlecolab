{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2024 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeadDkMiISin"
      },
      "source": [
        "# Gemini API: Prompting Quickstart\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google-gemini/cookbook/blob/main/quickstarts/Prompting.ipynb\"><img src=\"https://github.com/google-gemini/cookbook/blob/main/images/colab_logo_32px.png?raw=1\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpOYALec6N8Z"
      },
      "source": [
        "This notebook contains examples of how to write and run your first prompts with the Gemini API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0c13de5f68f6",
        "outputId": "08d4f1c0-f5db-4efd-fe8e-80462c40a3d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting aisuite\n",
            "  Downloading aisuite-0.1.6-py3-none-any.whl.metadata (5.7 kB)\n",
            "Downloading aisuite-0.1.6-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: aisuite\n",
            "Successfully installed aisuite-0.1.6\n"
          ]
        }
      ],
      "source": [
        "pip install aisuite"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install 'aisuite[all]'"
      ],
      "metadata": {
        "id": "srf8v6sGyI5D",
        "outputId": "89c4218b-e45e-48a0-b136-df13e6d8563a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: aisuite[all] in /usr/local/lib/python3.10/dist-packages (0.1.6)\n",
            "Collecting anthropic<0.31.0,>=0.30.1 (from aisuite[all])\n",
            "  Downloading anthropic-0.30.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting groq<0.10.0,>=0.9.0 (from aisuite[all])\n",
            "  Downloading groq-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.35.8 in /usr/local/lib/python3.10/dist-packages (from aisuite[all]) (1.54.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<0.31.0,>=0.30.1->aisuite[all]) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<0.31.0,>=0.30.1->aisuite[all]) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<0.31.0,>=0.30.1->aisuite[all]) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<0.31.0,>=0.30.1->aisuite[all]) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<0.31.0,>=0.30.1->aisuite[all]) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic<0.31.0,>=0.30.1->aisuite[all]) (1.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<0.31.0,>=0.30.1->aisuite[all]) (0.20.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from anthropic<0.31.0,>=0.30.1->aisuite[all]) (4.12.2)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.35.8->aisuite[all]) (4.66.6)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (2.27.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (0.26.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<0.31.0,>=0.30.1->aisuite[all]) (2.2.3)\n",
            "Downloading anthropic-0.30.1-py3-none-any.whl (863 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m863.9/863.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groq-0.9.0-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.5/103.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq, anthropic\n",
            "Successfully installed anthropic-0.30.1 groq-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install groq\n",
        "!pip install aisuite\n",
        "!pip nistall openai\n",
        "!pip install httpx==0.24.1"
      ],
      "metadata": {
        "id": "VmCPNtUfyQik",
        "outputId": "db83badc-e698-4544-c528-d899b0bd16ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: groq in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from groq) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from groq) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->groq) (2.27.1)\n",
            "Requirement already satisfied: aisuite in /usr/local/lib/python3.10/dist-packages (0.1.6)\n",
            "ERROR: unknown command \"nistall\" - maybe you meant \"uninstall\"\n",
            "Collecting httpx==0.24.1\n",
            "  Downloading httpx-0.24.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.1) (2024.8.30)\n",
            "Collecting httpcore<0.18.0,>=0.15.0 (from httpx==0.24.1)\n",
            "  Downloading httpcore-0.17.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.1) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.24.1) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx==0.24.1) (0.14.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx==0.24.1) (3.7.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx==0.24.1) (1.2.2)\n",
            "Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-0.17.3-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: httpcore, httpx\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.7\n",
            "    Uninstalling httpcore-1.0.7:\n",
            "      Successfully uninstalled httpcore-1.0.7\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "Successfully installed httpcore-0.17.3 httpx-0.24.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "groq_api_key = userdata.get('GROQ_API_KEY')\n",
        "os.environ['GROQ_API_KEY'] =groq_api_key"
      ],
      "metadata": {
        "id": "-Z8hxbV6zaAP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TS9l5igubpHO",
        "outputId": "6ab0278c-ad05-4c77-8bca-254be0494c27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'd be happy to explain Agentic AI to you. However, please note that I'm a text-based AI and cannot display images.\n",
            "\n",
            "**What is Agentic AI?**\n",
            "\n",
            "Agentic AI refers to a type of artificial intelligence (AI) that combines machine learning and cognitive architectures to simulate human-like decision-making, intentions, and agency. Agentic AI systems are designed to autonomously interact with their environment, make decisions based on their own goals and priorities, and adapt to new situations.\n",
            "\n",
            "Agentic AI is different from traditional AI systems, which typically rely on predetermined rules and algorithms to make decisions. Instead, agentic AI systems use a combination of machine learning and cognitive architectures to learn, reason, and act in their environment.\n",
            "\n",
            "**Key Characteristics of Agentic AI:**\n",
            "\n",
            "1. **Autonomy**: Agentic AI systems can make decisions without direct human intervention.\n",
            "2. **Agency**: Agentic AI systems have goals, intentions, and motivations that guide their behavior.\n",
            "3. **Learning**: Agentic AI systems learn from their experiences and adapt to new situations.\n",
            "4. **Cognitive Abstraction**: Agentic AI systems use cognitive architectures to represent and reason about complex information.\n",
            "\n",
            "**Examples of Agentic AI:**\n",
            "\n",
            "1. **Robotics**: Autonomous robots that can navigate and interact with their environment.\n",
            "2. ** autonomously driving cars**: Self-driving cars that can make decisions based on their sensors and map data.\n",
            "3. **Virtual assistants**: AI-powered virtual assistants, such as Alexa or Google Assistant, that can adapt to user preferences and conversation flow.\n",
            "\n",
            "**Benefits of Agentic AI:**\n",
            "\n",
            "1. **Improved decision-making**: Agentic AI systems can make decisions that are more informed and effective.\n",
            "2. **Increased autonomy**: Agentic AI systems can operate independently with minimal human intervention.\n",
            "3. **Enhanced creativity**: Agentic AI systems can generate novel solutions and ideas.\n",
            "\n",
            "If you're interested in learning more about agentic AI, I recommend exploring research articles and academic papers on the topic. However, please note that the field of agentic AI is rapidly evolving, and the information available may change over time.\n"
          ]
        }
      ],
      "source": [
        "import aisuite as ai\n",
        "client = ai.Client()\n",
        "\n",
        "provider = \"groq\"\n",
        "model_id = \"llama-3.2-3b-preview\"\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Tell me about Agentic AI and share some pictures\"},\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=f\"{provider}:{model_id}\",\n",
        "    messages=messages,\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4YDYyfRYN7L"
      },
      "source": [
        "## Set up your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or you're not sure how to create a Colab Secret, see the [Authentication](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Authentication.ipynb) quickstart for an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8K1RpmMfh20"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTNQymX8YN9c"
      },
      "source": [
        "## Run your first prompt\n",
        "\n",
        "Use the `generate_content` method to generate responses to your prompts. You can pass text directly to generate_content, and use the `.text` property to get the text content of the response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSuyaGmcf6sr",
        "outputId": "e00ca727-9eef-4441-d443-bbfe61770a06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```python\n",
            "# Using the built-in sort() method\n",
            "my_list = [5, 2, 8, 1, 9]\n",
            "my_list.sort()\n",
            "print(my_list)  # Output: [1, 2, 5, 8, 9]\n",
            "\n",
            "# Using the sorted() function (returns a new sorted list)\n",
            "my_list = [5, 2, 8, 1, 9]\n",
            "sorted_list = sorted(my_list)\n",
            "print(sorted_list)  # Output: [1, 2, 5, 8, 9]\n",
            "print(my_list)  # Output: [5, 2, 8, 1, 9] (original list remains unchanged)\n",
            "\n",
            "# Sorting in descending order\n",
            "my_list = [5, 2, 8, 1, 9]\n",
            "my_list.sort(reverse=True)\n",
            "print(my_list)  # Output: [9, 8, 5, 2, 1]\n",
            "\n",
            "# Sorting a list of tuples based on the second element\n",
            "my_list = [(1, 5), (3, 2), (2, 8)]\n",
            "my_list.sort(key=lambda x: x[1])\n",
            "print(my_list)  # Output: [(3, 2), (1, 5), (2, 8)]\n",
            "```\n",
            "\n",
            "**Explanation:**\n",
            "\n",
            "* **`my_list.sort()`:** This method sorts the list in place (modifies the original list).\n",
            "* **`sorted(my_list)`:** This function returns a new sorted list without modifying the original list.\n",
            "* **`reverse=True`:**  This argument to the `sort()` method sorts the list in descending order.\n",
            "* **`key=lambda x: x[1]`:** This argument to the `sort()` method specifies a function that extracts a value from each element to use for sorting. In this case, it sorts based on the second element of each tuple.\n",
            "\n",
            "Choose the method that best suits your needs based on whether you want to modify the original list or get a new sorted list.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "response = model.generate_content(\"Give me python code to sort a list\")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GTyrWHugKFi"
      },
      "source": [
        "## Use images in your prompt\n",
        "\n",
        "Here you will download an image from a URL and pass that image in our prompt.\n",
        "\n",
        "First, you download the image and load it with PIL:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgbFtil0gLNf",
        "outputId": "24895004-a42d-49fb-ff94-0bbe340e9ca6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  349k  100  349k    0     0  7591k      0 --:--:-- --:--:-- --:--:-- 7591k\n"
          ]
        }
      ],
      "source": [
        "!curl -o image.jpg \"https://storage.googleapis.com/generativeai-downloads/images/jetpack.jpg\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0rcYDbcDga8s",
        "outputId": "057bf6ab-4751-40c6-bfeb-911ea0903c50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/image.jpg'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-fde90790964b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'image.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3468\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3469\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3470\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3471\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/image.jpg'"
          ]
        }
      ],
      "source": [
        "import PIL.Image\n",
        "img = PIL.Image.open('image.jpg')\n",
        "img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTgRAmEHOaAz"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"This image contains a sketch of a potential product along with some notes.\n",
        "Given the product sketch, describe the product as thoroughly as possible based on what you\n",
        "see in the image, making sure to note all of the product features. Return output in json format:\n",
        "{description: description, features: [feature1, feature2, feature3, etc]}\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJyRsfQi0tp6"
      },
      "source": [
        "Then you can include the image in our prompt by just passing a list of items to `generate_content`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aoil5YiTgbZS",
        "outputId": "363d25d5-a76f-47e1-d6e8-d6ba9e534adb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```json\n",
            "{\n",
            " \"description\": \"The Jetpack Backpack is a backpack that looks like a normal backpack but has retractable boosters that allow the wearer to fly. It has a padded strap support, fits a 18 inch laptop, and has a USB-C charging port with 15-minute battery life. The boosters are steam-powered and green/clean.\",\n",
            " \"features\": [\n",
            "  \"Looks like a normal backpack\",\n",
            "  \"Padded strap support\",\n",
            "  \"Fits 18\\\" laptop\",\n",
            "  \"Retractable boosters\",\n",
            "  \"USB-C charging\",\n",
            "  \"15-minute battery life\",\n",
            "  \"Steam-powered\",\n",
            "  \"Green/clean\"\n",
            " ]\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "response = model.generate_content([prompt, img])\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE-6e7gePN7Q"
      },
      "source": [
        "## Have a chat\n",
        "\n",
        "The Gemini API enables you to have freeform conversations across multiple turns.\n",
        "\n",
        "The [ChatSession](https://ai.google.dev/api/python/google/generativeai/ChatSession) class will store the conversation history for multi-turn interactions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKAtY5oIPQW0"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "chat = model.start_chat(history=[])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tXNVnqxPcXy",
        "outputId": "c9e1aadf-ecc7-46dc-e101-39166de3101c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A computer is like a super smart toy that follows instructions from you, using numbers and lights to do amazing things! \n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = chat.send_message(\"In one sentence, explain how a computer works to a young child.\")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TChH2l5PhFf"
      },
      "source": [
        "You can see the chat history:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHwrC82YPiWS",
        "outputId": "4b9d6e72-2b02-4cf0-ca9a-c4f1b95113a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[parts {\n",
            "  text: \"In one sentence, explain how a computer works to a young child.\"\n",
            "}\n",
            "role: \"user\"\n",
            ", parts {\n",
            "  text: \"A computer is like a super smart toy that follows instructions from you, using numbers and lights to do amazing things! \\n\"\n",
            "}\n",
            "role: \"model\"\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "print(chat.history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvHvt1OEPl7D"
      },
      "source": [
        "You can keep sending messages to continue the conversation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fXZZQPzPkie"
      },
      "outputs": [],
      "source": [
        "response = chat.send_message(\"Okay, how about a more detailed explanation to a high schooler?\")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65476e75ece0"
      },
      "source": [
        "## Set the temperature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56f68c900144"
      },
      "source": [
        "Every prompt you send to the model includes parameters that control how the model generates responses. Use a `genai.GenerationConfig` to set these, or omit it to use the defaults.\n",
        "\n",
        "Temperature controls the degree of randomness in token selection. Use higher values for more creative responses, and lower values for more deterministic responses.\n",
        "\n",
        "You can set the `generation_config` when creating the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28477e706226"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel(\n",
        "    'gemini-1.5-flash',\n",
        "    generation_config=genai.GenerationConfig(\n",
        "        max_output_tokens=2000,\n",
        "        temperature=0.9,\n",
        "    ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3c68071ed8b"
      },
      "source": [
        "Or, set the `generation_config` on an individual call to `generate_content`. Any values set there override values on the model constructor.\n",
        "\n",
        "Note: Although you can set the `candidate_count` in the generation_config, gemini-pro models will only return a single candidate at the this time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f895c7f55b30"
      },
      "outputs": [],
      "source": [
        "response = model.generate_content(\n",
        "    'Give me a numbered list of cat facts.',\n",
        "    # Limit to 5 facts.\n",
        "    generation_config = genai.GenerationConfig(stop_sequences=['\\n6'])\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c97c16e6a961"
      },
      "outputs": [],
      "source": [
        "print(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvkDhXtHgol7"
      },
      "source": [
        "## Learn more\n",
        "\n",
        "There's lots more to learn!\n",
        "\n",
        "* For more fun prompts, check out [Market a Jetpack](https://github.com/google-gemini/cookbook/blob/main/examples/Market_a_Jet_Backpack.ipynb).\n",
        "* Check out the [safety quickstart](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Safety.ipynb) next to learn about the Gemini API's configurable safety settings, and what to do if your prompt is blocked.\n",
        "* For lots more details on using the Python SDK, check out this [detailed quickstart](https://ai.google.dev/tutorials/python_quickstart)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Prompting.ipynb",
      "provenance": []
    },
    "google": {
      "image_path": "/static/site-assets/images/docs/logo-python.svg",
      "keywords": [
        "examples",
        "gemini",
        "beginner",
        "googleai",
        "quickstart",
        "python",
        "text",
        "chat",
        "vision",
        "embed"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}